{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       False\n",
      "ZN         False\n",
      "INDUS      False\n",
      "CHAS       False\n",
      "NOX        False\n",
      "RM         False\n",
      "AGE        False\n",
      "DIS        False\n",
      "RAD        False\n",
      "TAX        False\n",
      "PTRATIO    False\n",
      "B          False\n",
      "LSTAT      False\n",
      "MEDV        True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('housing.csv')\n",
    "\n",
    "#In the steps below it was found that the column MEDV (Y) has NaN values. \n",
    "#Confirming and dropping them off\n",
    "\n",
    "print(data.isnull().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       False\n",
      "ZN         False\n",
      "INDUS      False\n",
      "CHAS       False\n",
      "NOX        False\n",
      "RM         False\n",
      "AGE        False\n",
      "DIS        False\n",
      "RAD        False\n",
      "TAX        False\n",
      "PTRATIO    False\n",
      "B          False\n",
      "LSTAT      False\n",
      "MEDV       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking all columns in data_dataframe, and defining the variables for the sets\n",
    "\n",
    "#print (data.keys())\n",
    "columns_regression = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "X = data[columns_regression]\n",
    "y = data['MEDV']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into learning and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the fitting\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Make prediction\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "Training: 0.7523932016050755,\n",
      "Tests: 0.7949292755607812\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score (y_test, y_test_pred)\n",
    "\n",
    "#Compute\n",
    "print(\"Score:\")\n",
    "print(f\"Training: {r2_score(y_train, y_train_pred)},\\nTests: {r2_score(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDV average is:21.215810276679843\n",
      "\n",
      "MSE:\n",
      "Training: 31.253313649105575,\n",
      "Tests: 22.31062669302033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"MEDV average is:{data['MEDV'].mean()}\\n\")\n",
    "\n",
    "print('MSE:')\n",
    "print(f\"Training: {mean_squared_error(y_train, y_train_pred)},\\nTests: {mean_squared_error(y_test, y_test_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean abolsute error for trainin set: 4.079237999224006\n",
      "Mean absolute error for test set: 4.079237999224006\n"
     ]
    }
   ],
   "source": [
    "#Calculate MAE for training set & test set\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error (y_train, y_train_pred)\n",
    "\n",
    "print(\"Mean abolsute error for trainin set:\", mae_train)\n",
    "print(\"Mean absolute error for test set:\", mae_test)\n",
    "\n",
    "#Lower values indicate better model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data_iris = load_iris()\n",
    "\n",
    "X_c = pd.DataFrame(data_iris[\"data\"], columns=data_iris[\"feature_names\"])\n",
    "y_c = pd.DataFrame(data_iris[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data_iris = pd.concat([X_c, y_c], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,8))\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "sns.set(rc={'figure.figsize':(6,6)});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Defining the predictor and response\n",
    "print (data_iris.keys())\n",
    "all_columns = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "x = data_iris[all_columns]\n",
    "y = data_iris['class']\n",
    "\n",
    "#split the data into training and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000)\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred_ = logreg.predict(x_train)\n",
    "y_test_pred_ =  logreg.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This function resolves the 8,9,10,11,12 & 13 exercices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set is: 0.975\n",
      "Accuracy score for test set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = accuracy_score(y_train, y_train_pred_)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred_)\n",
    "\n",
    "print(\"Accuracy score for training set is:\", accuracy_train)\n",
    "print(\"Accuracy score for test set is:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score for training set is: 0.975609756097561\n",
      "Balanced accuracy score for test set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "bal_acc_score_train = balanced_accuracy_score(y_train, y_train_pred_)\n",
    "bal_acc_score_test = balanced_accuracy_score(y_test, y_test_pred_)\n",
    "\n",
    "print(\"Balanced accuracy score for training set is:\", bal_acc_score_train)\n",
    "print(\"Balanced accuracy score for test set is:\", bal_acc_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for training set is: 0.975609756097561\n",
      "Precision score for test set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "prec_score_train = precision_score(y_train, y_train_pred_, average='macro')\n",
    "prec_score_test = precision_score(y_test, y_test_pred_, average= 'macro')\n",
    "\n",
    "print(\"Precision score for training set is:\", bal_acc_score_train)\n",
    "print(\"Precision score for test set is:\", bal_acc_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for training set is: 0.975609756097561\n",
      "Recall score for test set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "rec_score_train = recall_score(y_train, y_train_pred_, average='macro')\n",
    "rec_score_test = recall_score(y_test, y_test_pred_, average='macro')\n",
    "\n",
    "print(\"Recall score for training set is:\", rec_score_train)\n",
    "print(\"Recall score for test set is:\", rec_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set is: 0.9749960931395533\n",
      "F1 score for test set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "f1_train = f1_score(y_train, y_train_pred_, average='macro')\n",
    "f1_test = f1_score(y_test, y_test_pred_, average='macro')\n",
    "\n",
    "print(\"F1 score for training set is:\", f1_train)\n",
    "print(\"F1 score for test set is:\", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for training set is: [[40  0  0]\n",
      " [ 0 38  3]\n",
      " [ 0  0 39]]\n",
      "Confusion matrix for test set is: [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat_train = confusion_matrix(y_train, y_train_pred_)\n",
    "conf_mat_test = confusion_matrix(y_test, y_test_pred_)\n",
    "\n",
    "print(\"Confusion matrix for training set is:\", conf_mat_train)\n",
    "print(\"Confusion matrix for test set is:\", conf_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
