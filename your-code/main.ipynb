{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "data = pd.read_csv('housing.csv', header = None, delimiter = r\"\\s+\", names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CRIM - per capita crime rate by town\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - % lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['MEDV'], axis = 1)\n",
    "y = data['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lin_reg = LinearRegression()\n",
    "\n",
    "model_lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model_lin_reg.predict(X_train)\n",
    "y_pred_test = model_lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = model_lin_reg.score(X_train, y_train)\n",
    "r2_test = model_lin_reg.score(X_test, y_test)\n",
    "\n",
    "print('Training set r2-score:', r2_train)\n",
    "print('Testing set r2-score:', r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print('Training set MSE:', mse_train)\n",
    "print('Testing set MSE:', mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print('Training set MAE:', mae_train)\n",
    "print('Testing set MAE:', mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving split variables for bonus challenge:\n",
    "\n",
    "X_train_house = X_train\n",
    "X_test_house = X_test\n",
    "y_train_house = y_train\n",
    "y_test_house = y_test\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_log_reg = LogisticRegression()\n",
    "\n",
    "model_log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model_log_reg.predict(X_train)\n",
    "y_pred_test = model_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print('Training set accuracy:', train_acc)\n",
    "print('Testing set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "train_acc_balanced = balanced_accuracy_score(y_train, y_pred_train)\n",
    "test_acc_balanced = balanced_accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print('Training set accuracy (balanced):', train_acc_balanced)\n",
    "print('Testing set accuracy (balanced):', test_acc_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "train_prec = precision_score(y_train, y_pred_train, average = 'weighted')\n",
    "test_prec = precision_score(y_test, y_pred_test, average = 'weighted')\n",
    "\n",
    "print('Training set precision:', train_prec)\n",
    "print('Testing set precision:', test_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "train_rec = recall_score(y_train, y_pred_train, average = 'weighted')\n",
    "test_rec = recall_score(y_test, y_pred_test, average = 'weighted')\n",
    "\n",
    "print('Training set recall:', train_rec)\n",
    "print('Testing set recall:', test_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_f1 = f1_score(y_train, y_pred_train, average = 'weighted')\n",
    "test_f1 = f1_score(y_test, y_pred_test, average = 'weighted')\n",
    "\n",
    "print('Training set F1 score:', train_f1)\n",
    "print('Testing set F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_cm = confusion_matrix(y_train, y_pred_train)\n",
    "test_cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Training set confusion matrix:\\n', train_cm)\n",
    "print('Testing set confusion matrix:\\n', test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Housing dataset #\n",
    "###################\n",
    "\n",
    "print('##### BOSTON HOUSING DATASET #####\\n')\n",
    "\n",
    "# 1. Linear Regression (already done)\n",
    "# 2. Random Forest Regressor\n",
    "# 3. Gradient Boosting Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#####  1.  #####\n",
    "\n",
    "print('Linear Regression Metrics:')\n",
    "print('R2-score:\\t\\t', r2_test)\n",
    "print('Mean squared error:\\t', mse_test)\n",
    "print('Mean absolute error:\\t', mae_test, '\\n')\n",
    "\n",
    "#####  2.  #####\n",
    "\n",
    "model_rf = RandomForestRegressor(random_state = 42)\n",
    "model_rf.fit(X_train_house, y_train_house)\n",
    "y_pred_test_house = model_rf.predict(X_test_house)\n",
    "\n",
    "r2_test_house_rf = model_rf.score(X_test_house, y_test_house)\n",
    "mse_test_house_rf = mean_squared_error(y_test_house, y_pred_test_house)\n",
    "mae_test_house_rf = mean_absolute_error(y_test_house, y_pred_test_house)\n",
    "\n",
    "print('Random Forest Regressor Metrics:')\n",
    "print('R2-score:\\t\\t', r2_test_house_rf)\n",
    "print('Mean squared error:\\t', mse_test_house_rf)\n",
    "print('Mean absolute error:\\t', mae_test_house_rf, '\\n')\n",
    "\n",
    "#####  3.  #####\n",
    "\n",
    "model_gb = GradientBoostingRegressor(random_state = 42)\n",
    "model_gb.fit(X_train_house, y_train_house)\n",
    "y_pred_test_house = model_gb.predict(X_test_house)\n",
    "\n",
    "r2_test_house_gb = model_gb.score(X_test_house, y_test_house)\n",
    "mse_test_house_gb = mean_squared_error(y_test_house, y_pred_test_house)\n",
    "mae_test_house_gb = mean_absolute_error(y_test_house, y_pred_test_house)\n",
    "\n",
    "print('Gradient Boosting Regressor Metrics:')\n",
    "print('R2-score:\\t\\t', r2_test_house_gb)\n",
    "print('Mean squared error:\\t', mse_test_house_gb)\n",
    "print('Mean absolute error:\\t', mae_test_house_gb, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Iris dataset #\n",
    "################\n",
    "\n",
    "print('##### IRIS DATASET #####\\n')\n",
    "\n",
    "# 1. Logistic Regression (already done)\n",
    "# 2. K-Nearest Neighbors\n",
    "# 3. Support Vector Machine\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#####  1.  #####\n",
    "\n",
    "print('Logistic Regression Metrics:')\n",
    "print('Accuracy:\\t\\t', test_acc)\n",
    "print('F1-score:\\t\\t', test_f1)\n",
    "print('Precision:\\t\\t', test_prec, '\\n')\n",
    "\n",
    "#####  2.  #####\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "model_knn.fit(X_train, y_train)\n",
    "y_pred_test = model_knn.predict(X_test)\n",
    "\n",
    "acc_test_knn = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_knn = f1_score(y_test, y_pred_test, average = 'weighted')\n",
    "prec_test_knn = precision_score(y_test, y_pred_test, average = 'weighted')\n",
    "\n",
    "print('K-Nearest Neighbors Metrics:')\n",
    "print('Accuracy:\\t\\t', acc_test_knn)\n",
    "print('F1-score:\\t\\t', f1_test_knn)\n",
    "print('Precision:\\t\\t', prec_test_knn, '\\n')\n",
    "\n",
    "#####  3.  #####\n",
    "\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_test = model_svm.predict(X_test)\n",
    "\n",
    "acc_test_svm = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_svm = f1_score(y_test, y_pred_test, average = 'weighted')\n",
    "prec_test_svm = precision_score(y_test, y_pred_test, average = 'weighted')\n",
    "\n",
    "print('Support Vector Machine Metrics:')\n",
    "print('Accuracy:\\t\\t', acc_test_svm)\n",
    "print('F1-score:\\t\\t', f1_test_svm)\n",
    "print('Precision:\\t\\t', prec_test_svm, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Conclusion #\n",
    "##############\n",
    "\n",
    "# For the BOSTON DATASET, the Gradient Boosting Regressor is the best model.\n",
    "# It has the highest R2-score and the lowest errors (both MSE and MAE).\n",
    "\n",
    "# For the IRIS DATASET, the evaluation metrics are identical across the board.\n",
    "# There's no clear distinction in performance between the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
